{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb162d6b",
   "metadata": {},
   "source": [
    "# پروژه : ایجاد یک مدل ماشین لرنینگ و تشخیص احساس متن توسط یک رابط وب"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa5fdc7",
   "metadata": {},
   "source": [
    "وارد کردن کتاب خانه های مورد نیاز"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5308f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12185e4",
   "metadata": {},
   "source": [
    "مقدار دهی رابط وب با چند کد ساده و ایجاد بخشی برای وارد کردن متن مورد نظر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576de2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.write(\"# Text Emotions Prediction\")\n",
    "t1 = st.text_input(\"Enter any text>>: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a56b1",
   "metadata": {},
   "source": [
    "این تابع جهت خواندن دیتاست برای اموزش مدل پروژه است \n",
    "در این پروژه دیتا ست از قبل پیش پردازش شده و اماده است و فایل مورد نظر در ابتدا لیبل گذاری شده و سپس متن هر لیبل نوشته شده است\n",
    "که در اینجا لیبل های اول هر سطر جدا شده و بعنوان تارگت مورد استفاده قرار خواهند گرفت"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f140eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r')as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\")+1:].strip()\n",
    "            data.append([label, text])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717c240",
   "metadata": {},
   "source": [
    "در این بخش مسیر دیتا ست به تابع داده میشود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "394534df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n"
     ]
    }
   ],
   "source": [
    "file = 'text.txt'\n",
    "data = read_data(file)\n",
    "print(\"Number of instances: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ea0c9",
   "metadata": {},
   "source": [
    "این تابع دو ورودی میگیرد اولی برای متن و دومی یک عدد صحیح و یا یک بازه عددی \n",
    "کار این تابع جدا سازی حروف کلمات ب اندازه عدد صحیح میباشد و در اخر یک لیست ازحروف یک یا دو یا چند حرفی برمیگرداند "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e3cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(token, n): \n",
    "    output = []\n",
    "    for i in range(n-1, len(token)): \n",
    "        ngram = ' '.join(token[i-n+1:i+1])\n",
    "        output.append(ngram) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a65db3",
   "metadata": {},
   "source": [
    "تابع استخراج ویژگی ها دو ورودی مانند تابع بالا میگیرد عملکرد این تابع ب این صورت است که متن را بر اساس تکرار هایش در ان خط متن ب صورت دیکشنری دراورده و مقداد تکرارش را ب عنوان مقدار اون کلمه قرار میدهد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51758352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(text, nrange=(1, 1)):\n",
    "    text_features = [] \n",
    "    text = text.lower() \n",
    "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
    "    for n in range(nrange[0], nrange[1]+1): \n",
    "        text_features += ngram(text_alphanum.split(), n)    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    text_features += ngram(text_punc.split(), 1)\n",
    "    return Counter(text_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe92e6c",
   "metadata": {},
   "source": [
    "به عنوان مثال سه خط کد زیر را اجرا میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b69b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'i': 1, 'love': 1, 'you': 1, '!': 1})\n",
      "Counter({'aly': 1, 'wins': 1, 'the': 1, 'gold': 1, '!!!': 1})\n",
      "Counter({'aly': 1, 'wins': 1, 'the': 1, 'gold': 1, 'aly wins': 1, 'wins the': 1, 'the gold': 1, '!!!!!': 1})\n"
     ]
    }
   ],
   "source": [
    "print(create_feature(\"I love you!\"))\n",
    "print(create_feature(\" aly wins the gold!!!\"))\n",
    "print(create_feature(\" aly wins the gold!!!!!\", (1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e42ff",
   "metadata": {},
   "source": [
    "لیبل ها در این پروژه به صورت وان هات اینکودینگ است این تابع برای تبدیل این لیبل به یک کلمه که همان اسم احساس است مورد استفاده قرار میگیرد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e085e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(item, name): \n",
    "    items = list(map(float, item.split()))\n",
    "    label = \"\"\n",
    "    for idx in range(len(items)): \n",
    "        if items[idx] == 1: \n",
    "            label += name[idx] + \" \"\n",
    "    \n",
    "    return label.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20462efb",
   "metadata": {},
   "source": [
    "در این جا یک لیست ب اسم های احساس های موجود برای هر متن که در اخر همان لیبل ها میشود ایجاد میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6d9bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e27ac",
   "metadata": {},
   "source": [
    "حالا زمان ایجاد دیتای ویژگی ها و تارگت (لیبل ) ان ها است که از دو تابع از قبل نوشته شده استفاده میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46230e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features example: \n",
      "Counter({'time': 2, 'we': 2, 'met': 2, 'during': 1, 'the': 1, 'period': 1, 'of': 1, 'falling': 1, 'in': 1, 'love': 1, 'each': 1, 'that': 1, 'and': 1, 'especially': 1, 'when': 1, 'had': 1, 'not': 1, 'for': 1, 'a': 1, 'long': 1, 'during the': 1, 'the period': 1, 'period of': 1, 'of falling': 1, 'falling in': 1, 'in love': 1, 'love each': 1, 'each time': 1, 'time that': 1, 'that we': 1, 'we met': 1, 'met and': 1, 'and especially': 1, 'especially when': 1, 'when we': 1, 'we had': 1, 'had not': 1, 'not met': 1, 'met for': 1, 'for a': 1, 'a long': 1, 'long time': 1, 'during the period': 1, 'the period of': 1, 'period of falling': 1, 'of falling in': 1, 'falling in love': 1, 'in love each': 1, 'love each time': 1, 'each time that': 1, 'time that we': 1, 'that we met': 1, 'we met and': 1, 'met and especially': 1, 'and especially when': 1, 'especially when we': 1, 'when we had': 1, 'we had not': 1, 'had not met': 1, 'not met for': 1, 'met for a': 1, 'for a long': 1, 'a long time': 1, 'during the period of': 1, 'the period of falling': 1, 'period of falling in': 1, 'of falling in love': 1, 'falling in love each': 1, 'in love each time': 1, 'love each time that': 1, 'each time that we': 1, 'time that we met': 1, 'that we met and': 1, 'we met and especially': 1, 'met and especially when': 1, 'and especially when we': 1, 'especially when we had': 1, 'when we had not': 1, 'we had not met': 1, 'had not met for': 1, 'not met for a': 1, 'met for a long': 1, 'for a long time': 1, ',': 1, '.': 1})\n",
      "Label example:\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "X_all = []\n",
    "y_all = []\n",
    "for label, text in data:\n",
    "    y_all.append(convert_label(label, emotions))\n",
    "    X_all.append(create_feature(text, nrange=(1, 4)))\n",
    "\n",
    "print(\"features example: \")\n",
    "print(X_all[0])\n",
    "print(\"Label example:\")\n",
    "print(y_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1f60e",
   "metadata": {},
   "source": [
    "این کد برای جدا سازی دیتای مورد نیاز برای اموزش مدل و تست میباشد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a707e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a7f98",
   "metadata": {},
   "source": [
    "این تابع نوع کلاس طبقه بندی و دیتاهای مورد نیاز را میگیرد و درصد موفقیت روی دیتای اموزش و تست برمیگرداند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c26ca2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    return train_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a93c5",
   "metadata": {},
   "source": [
    "در این بخش چون دیتای ما بصورت دیکشنری است ابتدا توسط این کلاس به یک وکتور که ورودی مدل ماشین لرنینگ ما است اماده میشود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4584aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse = True)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247dbb6",
   "metadata": {},
   "source": [
    "انواع کلاس های طبقه بندی ایجاد و لیستی از انها برای دادن بع تابع بالا ایجاد میشود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a9aa182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers \n",
    "svc = SVC()\n",
    "lsvc = LinearSVC(random_state=123)\n",
    "rforest = RandomForestClassifier(random_state=123)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "clifs = [svc, lsvc, rforest, dtree]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc94d3",
   "metadata": {},
   "source": [
    "و در این مرحله یک حلقه برای اعمال هر 4 کلاس طبقه بندی به تابع قبل ایجاد میکنیم و نتایج هرکدام رو در خروجی چاپ میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50035a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
    "for clf in clifs: \n",
    "    clf_name = clf.__class__.__name__\n",
    "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
    "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))\n",
    "\n",
    "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "l.sort()\n",
    "label_freq = {}\n",
    "for label, _ in data: \n",
    "    label_freq[label] = label_freq.get(label, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f07f5e",
   "metadata": {},
   "source": [
    "و در اخرین بخش این پروژه پیش بینی شده توسط ماشین به یک ایموجی مشخص شده در زیر تبدیل شده و در رابط وب نمایش داده میشود "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the labels and their counts in sorted order \n",
    "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))\n",
    "\n",
    "emoji_dict = {\"joy\":\"😂\", \"fear\":\"😱\", \"anger\":\"😠\", \"sadness\":\"😢\", \"disgust\":\"😒\", \"shame\":\"😳\", \"guilt\":\"😳\"}\n",
    "\n",
    "texts = [t1]\n",
    "for text in texts: \n",
    "    features = create_feature(text, nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    prediction = clf.predict(features)[0]\n",
    "    st.write(emoji_dict[prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
